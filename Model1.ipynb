{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.layers import Activation, Input, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adadelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '/home/evren/classified_data/clean_data/'\n",
    "noisy_15dB_path = '/home/evren/classified_data/noisy_data/15dB'\n",
    "noisy_20dB_path = '/home/evren/classified_data/noisy_data/20dB'\n",
    "noisy_25dB_path = '/home/evren/classified_data/noisy_data/25dB'\n",
    "noisy_30dB_path = '/home/evren/classified_data/noisy_data/30dB'\n",
    "noisy_100dB_path = '/home/evren/classified_data/noisy_data/100dB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 69071 images belonging to 1 classes.\n",
      "Found 69071 images belonging to 1 classes.\n",
      "Found 69071 images belonging to 1 classes.\n",
      "Found 69071 images belonging to 1 classes.\n",
      "Found 69071 images belonging to 1 classes.\n",
      "Found 69071 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# class_mode='input': images identical to input images (mainly used to work with autoencoders)\n",
    "# seed: Optional random seed for shuffling and transformations.\n",
    "# it yields float32 tensors of shape (batch_size, *target_size, channels)\n",
    "# all imgs height is 64, width changes between approximately 100-500\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "                           train_data_path,target_size=(64,128), shuffle=False, class_mode='input', seed=42)\n",
    "\n",
    "test_15dB_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "                           noisy_15dB_path,target_size=(64,128), shuffle=False, class_mode='input', seed=42)\n",
    "\n",
    "test_20dB_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "                           noisy_20dB_path,target_size=(64,128), shuffle=False, class_mode='input', seed=42)\n",
    "\n",
    "test_25dB_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "                           noisy_25dB_path,target_size=(64,128), shuffle=False, class_mode='input', seed=42)\n",
    "\n",
    "test_30dB_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "                           noisy_30dB_path,target_size=(64,128), shuffle=False, class_mode='input', seed=42)\n",
    "\n",
    "test_100dB_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "                           noisy_100dB_path,target_size=(64,128), shuffle=False, class_mode='input', seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69071, 64, 128, 3)\n",
      "69071\n",
      "(69071, 64, 128, 3)\n",
      "69071\n"
     ]
    }
   ],
   "source": [
    "train_data=np.concatenate([train_generator.next()[0] for i in range(train_generator.__len__())])\n",
    "print(train_data.shape)\n",
    "print(len(train_data))\n",
    "\n",
    "test_15dB_data=np.concatenate([test_15dB_generator.next()[0] for i in range(test_15dB_generator.__len__())])\n",
    "print(test_15dB_data.shape)\n",
    "print(len(test_15dB_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_train, x_test, clean_train, y_test = train_test_split(test_15dB_data, train_data,\n",
    "                                                           test_size=20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data=[]\n",
    "#train_generator.reset()\n",
    "#for i in range(train_generator.__len__()):\n",
    "#    a,b = train_generator.next()\n",
    "#    train_data.append(a)\n",
    "\n",
    "#train_data=np.array(train_data)\n",
    "#print(len(train_data))\n",
    "\n",
    "\n",
    "#test_15dB_data=[]\n",
    "#test_15dB_generator.reset()\n",
    "#for i in range(test_15dB_generator.__len__()):\n",
    "#    a,b = test_15dB_generator.next()\n",
    "#    test_15dB_data.append(a)\n",
    "\n",
    "#test_15dB_data=np.array(test_15dB_data)\n",
    "#print(test_15dB_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_ep = train_generator.n // train_generator.batch_size\n",
    "# validation_st = val_generator.n // val_generator.batch_size\n",
    "\n",
    "test_15dB_steps= test_15dB_generator.n // test_15dB_generator.batch_size\n",
    "test_20dB_steps= test_20dB_generator.n // test_20dB_generator.batch_size\n",
    "test_25dB_steps= test_25dB_generator.n // test_25dB_generator.batch_size\n",
    "test_30dB_steps= test_30dB_generator.n // test_30dB_generator.batch_size\n",
    "test_100dB_steps= test_100dB_generator.n // test_100dB_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    \n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(64,128,3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(8, (3, 3), activation='relu', padding='same'), \n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    \n",
    "    #Flatten(),\n",
    " \n",
    "    Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(1, (3, 3), activation='relu', padding='same')\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 64, 128, 32)       896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 64, 128, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 64, 8)         2312      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 64, 8)         32        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 32, 8)         584       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 32, 8)         32        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 16, 8)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 16, 8)          584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 16, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 32, 8)         584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 32, 64, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 64, 32)        2336      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 64, 128, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 64, 128, 1)        289       \n",
      "=================================================================\n",
      "Total params: 7,777\n",
      "Trainable params: 7,681\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='mse',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`y` argument is not supported when using `keras.utils.Sequence` as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-695af69fc5fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(test_15dB_generator, train_generator,\n\u001b[0;32m----> 2\u001b[0;31m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                 )\n",
      "\u001b[0;32m/home/evren/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/home/evren/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/evren/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2.pyc\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/evren/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2.pyc\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/evren/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/data_adapter.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, standardize_function, shuffle, workers, use_multiprocessing, max_queue_size, **kwargs)\u001b[0m\n\u001b[1;32m    936\u001b[0m                max_queue_size=10, **kwargs):\n\u001b[1;32m    937\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_none_or_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m       raise ValueError(\"`y` argument is not supported when using \"\n\u001b[0m\u001b[1;32m    939\u001b[0m                        \"`keras.utils.Sequence` as input.\")\n\u001b[1;32m    940\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_none_or_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `y` argument is not supported when using `keras.utils.Sequence` as input."
     ]
    }
   ],
   "source": [
    "history = model.fit(test_15dB_generator, train_generator,\n",
    "                epochs=20\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model1.h5')\n",
    "\n",
    "train_loss, train_acc = model.evaluate(train_generator)\n",
    "val_loss, val_acc = model.evaluate(val_generator) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (17,6)\n",
    "fig, ax1 = plt.subplots()\n",
    "xepochs = range(1,len(history.history['loss']) + 1)\n",
    "\n",
    "plt.plot(xepochs, history.history['loss'], label = 'loss')\n",
    "plt.plot(xepochs, history.history['val_loss'], label = 'val_loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(xepochs, history.history['accuracy'], label = 'accuracy')\n",
    "plt.plot(xepochs, history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.title('Metrics (Accuracy)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_15dB = model.predict(test_15dB_generator, \n",
    "                           steps=test_15dB_steps)\n",
    "\n",
    "prediction_20dB = model.predict(test_20dB_generator, \n",
    "                           steps=test_20dB_steps)\n",
    "\n",
    "prediction_25dB = model.predict(test_25dB_generator, \n",
    "                           steps=test_25dB_steps)\n",
    "\n",
    "prediction_30dB = model.predict(test_30dB_generator, \n",
    "                           steps=test_30dB_steps)\n",
    "\n",
    "prediction_100dB = model.predict(test_100dB_generator, \n",
    "                           steps=test_100dB_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_100dB_arr, labels = next(test_100dB_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplot(1,10, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotImages(test_100dB_generator)\n",
    "plotImages(prediction_100dB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(original, compressed): \n",
    "    mse = np.mean((original - compressed) ** 2) \n",
    "    if(mse == 0):  # MSE is zero means no noise is present in the signal . \n",
    "                  # Therefore PSNR have no importance. \n",
    "        return 100\n",
    "    max_pixel = 255.0\n",
    "    psnr = 20 * log10(max_pixel / sqrt(mse)) \n",
    "    return psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSNR(test_100dB_generator, prediction_100dB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
